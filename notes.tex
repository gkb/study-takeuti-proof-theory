\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{mathrsfs}
\usepackage{hyperref}
\usepackage{MnSymbol}
\usepackage[dvipsnames]{xcolor}
\usepackage{bussproofs}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\DeclareMathOperator{\LK}{\textbf{LK}}
\def\fCenter{\mbox{\Large$\rightarrow$}}

\title{Notes from Proof Theory by Takeuti}
\author{gajukbhat}
\date{April 2022}

\def\fCenter{\mbox{$\rightarrow$}}

\begin{document}

\maketitle

\section{Chapter 1}
\subsection{Lemma 2.12}
Make the proof regular to get \(P''(a)\). If the proof contains no eigenvariables that are \(a\) or contained in \(t\), then \(P'(a) = P''(a)\).
Let the induction hypothesis be that if the proof contains up to \(n\) eigenvariables that are \(a\) or contained in \(t\), then there's a \(P'(a)\) derived from \(P(a)\) that is a proof of \(\Gamma(a) \rightarrow \Delta(a)\). It's possible to show that the induction hypothesis implies that if the proof contains \(n + 1\) eigenvariables that are \(a\) or contained in \(t\), then there's a \(P'(a)\) derived from \(P(a)\) that is a proof of \(\Gamma(a) \rightarrow \Delta(a)\).
From that the conclusion follows.

\subsection{Definition 2.15}
I want to prove that the definition defines an equivalence relation. Suppose for some \(u_1, \ldots, u_n\) and \(v_1, \ldots, v_n\)
% TODO: Create a macro to make typing this easier.
\[
    A\biggl(\frac{u_1, \ldots, u_m}{w_1, \ldots, w_m}\biggr)
\]
and
\[
    B\biggl(\frac{v_1, \ldots, v_m}{w_1, \ldots, w_m}\biggr)
\]
are the same. And suppose for some \(x_1, \ldots, x_n\) and \(y_1, \ldots, y_n\)
\[
    B\biggl(\frac{x_1, \ldots, x_n}{z_1, \ldots, z_n}\biggr)
\]
and
\[
    C\biggl(\frac{y_1, \ldots, y_n}{z_1, \ldots, z_n}\biggr)
\]
are identical.

Later, there's a claim that we can prove by induction on the number of logical symbols in \(A\) that if \(A \sim B\), then \(A \equiv B\) is provable without cut.
I could get it if I took \(A \equiv B\) to mean \(A \rightarrow B\) and \(B \rightarrow A\).
Once I apply any one of the rules of sequent calculus, there's no going back. The formulae only get more complex.
Wait until I learn more about cut elimination and keep going with what I have.

\subsection{Exercise 3.11}
    \begin{description}
        % TODO: See if I really need to add a colon after the item description argument.
        \item[Outermost symbol is \(\supset\):]
        Assume there are \textbf{LJ}-proofs of the sequents \(\neg\neg A \rightarrow A\)
        and \(\neg \neg B \rightarrow B\).
        Let me prove the sequent \(\neg \neg (A \supset B) \rightarrow (A \supset B)\).
        PS-This one's actually easy when I use the result of (1) from Exercise 3.10 and the cut formula.
        I got the rest as well.
%            \begin{prooftree}
%                \Axiom$A, \fCenter\ B$
%                \UnaryInf$A, B \fCenter\ C$
%            \end{prooftree}
    \end{description}
I got the rest as well.

\subsection{Proposition 4.3}
If there are no inferences, then clearly a sequent \(\Gamma \rightarrow \Delta\) is \(\LK_\mathcal{A}\)-provable
only if \(\Gamma \rightarrow \Delta\) is provable from \(\mathcal{A}\) in \(\LK\).

\subsection{Lemma 5.4}
I'm trying to deal with the case of \(\supset\)-left when  \(r_r(P) = 1\) and \(r_l(P) > 1\). Mancosu pointed it out as needing special attention.

\subsection{Exercise 6.7}
There's a cut-free proof for the sequent \(A \fCenter B\) that has a mid-sequent.
Use induction on the number of inferences in the proof with the mid-sequent, Take the example of
a \(\land\)-right inference above a mid-sequent. If \(C_1\) and \(C_2\) are the interpolants for the two
upper sequents for the inference, \(C_1 \land C_2\) is the interpolant of the lower sequent.

For the case with no inferences, \(A\) is the same as \(B\) and is atomic. \(C = A\) suffices.

\subsection{Review of Cut Elimination}
\begin{enumerate}
\item We have a double induction on \(\omega g + r\) where \(g\) is the grade and \(r\) is the rank.
\item The case of \(r = 2\) is where I want to start.
\end{enumerate}

\subsection{Theorem 6.9}
There are two cases I can distinguish when the condition that there's no semi-sub-term of \(t\) in \(S\)
isn't satisfied.
\begin{description}
\item[Case 1:] a sub-semi-term occurs in the same formula
\item[Case 2:] a sub-semi-term occurs in a different formula.
\end{description}
Then look at quantifier inferences.

Let's say there are terms \(f(a, b)\) and \(g(f(c, b), d)\) in different formulas in the upper sequent and
there are terms \(f(x_1, b)\) and \(g(f(c, b), d)\) in the lower sequent. \(x_1\) is a bound variable.

It's clear that \(\forall\) : left and \(\exists\) : right are the two rules I need to worry about.

No wait, I have to look at the other two rules as well. None of the inferences alter terms. That's
important to note.

Conclusion: I'm a bit confused. In the comments on the book, the steps to remove my confusion
are made clear.
% Now what happens when the condition is satisfied. I'm dealing with a regular proof.
\end{document}
